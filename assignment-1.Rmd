---
title: "Prediction Assignment Writeup"
author: "Jia Sheng Chong"
date: "10/30/2019"
output:
  html_document:
    keep_md: true
---

```{r echo=TRUE}
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
library(ggplot2)
library(GGally)
library(caret)
library(klaR)
library(kernlab)
library(corrplot)
library(knitr)
library(readr)

set.seed(666)
```

## Overview
The purpose of this report is to predict the manner in which a person has done an exercise. The main aim of this report is to predict the manner of 6 different particpants and their exercise.


## Data Analysis
```{r echo=TRUE}
raw <- data.frame()
raw.test  <- read_csv(file = './data/pml_testing.csv', col_names = TRUE)
raw.train <- read_csv(file = './data/pml_training.csv', col_names = TRUE)

dim(raw.test)
dim(raw.train)

# Calculating the percentage of test to training data provided
(dim(raw.test)[1]/dim(raw.train)[1]) * 100

# Percentage of classes
percentage <- prop.table(table(raw.train$classe)) * 100
cbind(freq=table(raw.train$classe), percentage = percentage)

```
We can observe there are 160 columns for the data provided to us. The test data we have been given contains 20 rows, while the training data contains 19622 rows. However, because the percentage of testing data to training data is 0.1%, I will use the training data to create my own test data and perform cross validation. After which, I will use the final model created to predict the test data that was initially provided. 

### Cleaning Data
As the given testing data contains columns which only contains NA values, we will remove these columns as they are worthless for predicting our test data. We also remove the first 5 columns as they provide no value to our models.
```{r echo = TRUE}
# Clean data, clean data which contains only NA values
clean <- data.frame()
keepCol <- colSums(is.na(raw.test)) < nrow(raw.test)
clean.test <- raw.test[,keepCol]
clean.train <- raw.train[,keepCol]

# Remove useless information
clean.test <- clean.test[,-c(1:5)]
clean.train <- clean.train[,-c(1:5)]

clean.train$classe <- factor(clean.train$classe)

# Remove any data that contains NA in the any columns
clean.trainNoNA <- data.frame(na.omit(clean.train))
dim(clean.trainNoNA)

```

## Using Cross Validation
To train and test our models, we will use cross validation (5 folds). We use cross validation so that we can use our model to predict over all our data. Using this method means that we do not have to split our data as the cross validation already does that for us.
```{r echo = TRUE}
forTrain.data <- clean.trainNoNA
forTrain.control <- trainControl(method = 'cv', number = 5)
```

## Training and building the model
To build our final model, I will use 3 different algorithms, knn, svm and lda.
```{r echo = TRUE}
predictions <- data.frame()

model.knn <- train(classe ~ ., data = forTrain.data, method = 'knn', trControl = forTrain.control)

model.svm <- train(classe ~ ., data = forTrain.data, method = 'svmRadial', trControl = forTrain.control)

model.lda <- train(classe ~ ., data = forTrain.data, method = 'lda', trControl = forTrain.control)

# Compare accuracy
results <- resamples(list(knn=model.knn, svm=model.svm, lda=model.lda))
summary(results)

summary(model.svm)
```
After training our models, I compare them using the resamples function. In the summary of our results, we can see that performed the best accuracy over knn and lda. Hence, we will use svm to predict the assignment's test data.

## Sample Error
Using our svm model to predict our training model, we get an out of sample error of 5.28%.
```{r echo = TRUE}
trainPredict <- predict(model.svm, newdata = clean.train)
confusionMatrix(trainPredict, clean.train$classe)
```

## Final Prediction
```{r echo = TRUE}
finalPredict <- predict(model.svm, newdata = clean.test)
finalPredict
```

