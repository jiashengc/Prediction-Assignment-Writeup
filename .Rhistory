avgStepsByWe <- aggregate(filledAct$steps, by = list(Interval = filledAct$interval, Day = filledAct$DayType), FUN = mean)
ggplot(filledAct, mapping = aes(interval, x)) +
geom_line()
ggplot(avgStepsByWe, mapping = aes(interval, x)) +
geom_line()
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line()
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day))
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
title("Average Steps Across Weekday/Weekeends")
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
main("Average Steps Across Weekday/Weekeends")
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
ggtitle("Average Steps Across Weekday/Weekeends")
setwd("C:/Users/jiash/Dropbox/R-repo/RepData_PeerAssessment1")
activity <- read.csv("activity/activity.csv",
header = TRUE,
na.string = "?",
colClasses = c("numeric", NA, "numeric"))
activity$newDate = as.Date(activity$date, format = "%Y-%m-%d")
stepsByDay <- aggregate(activity$steps, by = list(Day = activity$newDate), FUN = sum, na.rm = TRUE)
hist(stepsByDay$x, main = "Total Number of Steps Per Day", xlab = "Steps")
mean(stepsByDay$x)
median(stepsByDay$x)
avgDailyAct <- aggregate(activity$steps, by = list(Interval = activity$interval), FUN = mean, na.rm = TRUE)
plot(avgDailyAct$Interval, avgDailyAct$x, type = "l", xlab= "Interval", ylab = "Average Steps", main="Average Daily Activity Pattern")
avgDailyAct[avgDailyAct$x == max(avgDailyAct$x),]
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
ggtitle("Average Steps Across Weekday/Weekeends")
filledAct$Day <- weekdays(filledAct$newDate, abbreviate = FALSE)
weekdays <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday')
filledAct$DayType <- factor(filledAct$Day %in% weekdays, labels = c('Weekend', 'Weekday'))
avgStepsByWe <- aggregate(filledAct$steps, by = list(Interval = filledAct$interval, Day = filledAct$DayType), FUN = mean)
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
ggtitle("Average Steps Across Weekday/Weekeends")
activity <- read.csv("activity/activity.csv",
header = TRUE,
na.string = "?",
colClasses = c("numeric", NA, "numeric"))
activity$newDate = as.Date(activity$date, format = "%Y-%m-%d")
## What is mean total number of steps taken per day?
```{r echo = TRUE}
stepsByDay <- aggregate(activity$steps, by = list(Day = activity$newDate), FUN = sum, na.rm = TRUE)
hist(stepsByDay$x, main = "Total Number of Steps Per Day", xlab = "Steps")
# Mean of total number of steps taken per day
mean(stepsByDay$x)
# Median of total number of steps taken per day
median(stepsByDay$x)
# Median of total number of steps taken per day
median(stepsByDay$x)
## What is the average daily activity pattern?
```{r echo = TRUE}
avgDailyAct <- aggregate(activity$steps, by = list(Interval = activity$interval), FUN = mean, na.rm = TRUE)
plot(avgDailyAct$Interval, avgDailyAct$x, type = "l", xlab= "Interval", ylab = "Average Steps", main="Average Daily Activity Pattern")
# Across the dataset, the following contains the max no of steps
avgDailyAct[avgDailyAct$x == max(avgDailyAct$x),]
## Imputing missing values
```{r echo = TRUE}
sum(is.na(activity))
missingCol <- colnames(activity)[apply(activity, 2, anyNA)]
filledAct <- activity
filledAct$newDate = as.Date(filledAct$date, format = "%Y-%m-%d")
# We group by interval in this case because some dates do not have steps recorded e.g. 2012-10-01
filledAct$steps <- ave(filledAct$steps, filledAct$interval, FUN = function(x) {
ifelse(is.na(x), mean(x, na.rm = TRUE), x)
})
filledActByDay <- aggregate(filledAct$steps, by = list(day = filledAct$newDate), FUN = sum)
hist(filledActByDay$x, main = "Total number of Steps Each Day", xlab = "Steps")
# Mean of total number of steps taken per day
mean(filledActByDay$x)
# Median of total number of steps taken per day
median(filledActByDay$x)
```{r echo = TRUE}
avgStepsByWe <- aggregate(filledAct$steps, by = list(Interval = filledAct$interval, Day = filledAct$DayType), FUN = mean)
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
ggtitle("Average Steps Across Weekday/Weekeends")
sum(is.na(activity))
missingCol <- colnames(activity)[apply(activity, 2, anyNA)]
filledAct <- activity
filledAct$newDate = as.Date(filledAct$date, format = "%Y-%m-%d")
# We group by interval in this case because some dates do not have steps recorded e.g. 2012-10-01
filledAct$steps <- ave(filledAct$steps, filledAct$interval, FUN = function(x) {
ifelse(is.na(x), mean(x, na.rm = TRUE), x)
})
filledActByDay <- aggregate(filledAct$steps, by = list(day = filledAct$newDate), FUN = sum)
hist(filledActByDay$x, main = "Total number of Steps Each Day", xlab = "Steps")
# Mean of total number of steps taken per day
mean(filledActByDay$x)
# Median of total number of steps taken per day
median(filledActByDay$x)
```{r echo = TRUE}
avgStepsByWe <- aggregate(filledAct$steps, by = list(Interval = filledAct$interval, Day = filledAct$DayType), FUN = mean)
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
ggtitle("Average Steps Across Weekday/Weekeends")
avgStepsByWe <- aggregate(filledAct$steps, by = list(Interval = filledAct$interval, Day = filledAct$DayType), FUN = mean)
filledAct$Day <- weekdays(filledAct$newDate, abbreviate = FALSE)
weekdays <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday')
filledAct$DayType <- factor(filledAct$Day %in% weekdays, labels = c('Weekend', 'Weekday'))
avgStepsByWe <- aggregate(filledAct$steps, by = list(Interval = filledAct$interval, Day = filledAct$DayType), FUN = mean)
ggplot(avgStepsByWe, mapping = aes(Interval, x)) +
geom_line() +
facet_grid(rows = vars(Day)) +
ylab("Average Steps") +
ggtitle("Average Steps Across Weekday/Weekeends")
# Mean of total number of steps taken per day (Missing Values)
mean(filledActByDay$x)
# Mean of total number of steps taken per day (Normal)
mean(stepsByDay$x)
# Median of total number of steps taken per day (Missing Values)
median(filledActByDay$x)
# Median of total number of steps taken per day (Normal)
median(stepsByDay$x)
# Mean of total number of steps taken per day (Missing Values)
mean(filledActByDay$x)
# Mean of total number of steps taken per day (Normal)
mean(stepsByDay$x)
# Median of total number of steps taken per day (Missing Values)
median(filledActByDay$x)
# Median of total number of steps taken per day (Normal)
median(stepsByDay$x)
# Median of total number of steps taken per day (Missing Values)
median(filledActByDay$x)
# Median of total number of steps taken per day (Normal)
median(stepsByDay$x)
# Mean of total number of steps taken per day (Replaced Values)
mean(filledActByDay$x)
# Mean of total number of steps taken per day (Normal)
mean(stepsByDay$x)
# Mean of total number of steps taken per day (Replaced Values)
mean(filledActByDay$x)
# Mean of total number of steps taken per day (Normal)
mean(stepsByDay$x)
# Median of total number of steps taken per day (Replaced Values)
median(filledActByDay$x)
# Median of total number of steps taken per day (Normal)
median(stepsByDay$x)
# Median of total number of steps taken per day (Replaced Values)
median(filledActByDay$x)
# Median of total number of steps taken per day (Normal)
median(stepsByDay$x)
# Median of total number of steps taken per day (Replaced Values)
median(filledActByDay$x)
# Median of total number of steps taken per day (Normal)
median(stepsByDay$x)
setwd("C:/Users/jiash/Dropbox/R-repo/RepData_PeerAssessment1")
library(ggplot2)
library(ggplot2)
library(dplyr)
read.csv("repdata_data_StormData.csv.bz2")
read.csv("repdata_data_StormData.csv.bz2")
stormData <- read.csv("repdata_data_StormData.csv.bz2")
View(stormData)
session_info()
session_info()
setwd("C:/Users/jiash/Dropbox/R-repo/c5-cp2")
stormData <- read.csv("repdata_data_StormData.csv.bz2")
sum(is.na(stormData))
fatalByEvents <- aggregate(stormData$FATALITIES, by = list(events = stormData$EVTYPE), FUN = sum, na.rm = TRUE)
injuriesByEvents <- aggregate(stormData$INJURIES, by = list(events = stormData$EVTYPE), FUN = sum, na.rm = TRUE)
fatalByEvents <- aggregate(stormData$FATALITIES + stormData$INJURIES, by = list(events = stormData$EVTYPE), FUN = sum, na.rm = TRUE)
View(fatalByEvents)
healthByEvents <-
stormData %>%
group_by(FATALITIES, INJURIES) %>%
summarise_each(funs(sum))
healthByEvents <-
stormData %>%
group_by(FATALITIES, INJURIES) %>%
summarise_each(funs(mean))
tinytex::install_tinytex()
library(swirl)
swirl()
ols.ic <- fit$coef
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
rhs - lhs
lsh - rhs
lhs - rhs
all.squal(lhs, rhs)
all.equal(lhs, rhs)
var(varChild)
1
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varESt <- var(ols.slope, ols.ic)
varESt <- var(est(ols.slope, ols.ic))
varEst <- var(est(ols.slope, ols.ic))
all.equal(varRes, varEstr)
all.equal(varRes, varEst)
all.equal(varChild, varEst + varRest)
all.equal(varChild, varEst + varRes)
efit <- lm(accel ~ mag + dist, attenu)
mean(efit)
mean(efit$residuals)
cov(attenu$mag)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor(gpa_nor, gch_nor)
l_nor <- lm(gpa_nor, gch_nor)
l_nor <- lm()
l_nor <- lm(1,2)
1
l_nor <- lm(gch_nor ~ gpa_nor)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
x[1]
x[0]
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mu <- sum(x *w) / sum(w)
mu
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x ~ y)
lm(y ~ x)
lm(y ~ x - 1)
data(mtcars)
lm(mtcars$mpg, mtcars$wt)
lm(mtcars$mpg ~ mtcars$wt)
stdev <- 1
corr <- .5
mean <- 0
variance <- 1
corr <- 0.4
quiz1 <- 1.5
quiz2 <- mean + corr * 1.5
quiz2
swirl()
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(GGally)
library(caret)
library(klaR)
library(kernlab)
library(corrplot)
set.seed(666)
predictions <- data.frame()
model.knn <- train(classe ~ ., data = train.data, method = 'knn', trControl = train.control)
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
library(ggplot2)
library(GGally)
library(caret)
library(klaR)
library(kernlab)
library(corrplot)
set.seed(666)
raw <- data.frame()
raw.test  <- read.csv(file = 'pml-testing.csv', header = TRUE)
raw.train <- read.csv(file = 'pml-training.csv', header = TRUE)
dim(raw.test)
dim(raw.train)
# Calculating the percentage of test to training data provided
(dim(raw.test)[1]/dim(raw.train)[1]) * 100
# Percentage of classes
percentage <- prop.table(table(raw.train$classe)) * 100
cbind(freq=table(raw.train$classe), percentage = percentage)
# Clean data, clean data which contains only NA values
clean <- data.frame()
keepCol <- colSums(is.na(raw.test)) < nrow(raw.test)
clean.test <- raw.test[,keepCol]
clean.train <- raw.train[,keepCol]
clean.train$classe <- factor(clean.train$classe)
# Remove any data that contains NA in the any columns
clean.trainNoNA <- data.frame(na.omit(clean.train))
dim(clean.trainNoNA)
train <- data.frame()
train.data <- clean.trainNoNA
train.control <- trainControl(method = 'cv', number = 5)
predictions <- data.frame()
model.knn <- train(classe ~ ., data = train.data, method = 'knn', trControl = train.control)
predictions.knn <- predict(model.knn, test.data)
confusionMatrix(predictions.knn, test.data$classe)
model.svm <- train(classe ~ ., data = train.data, method = 'svmRadial', trControl = train.control)
model.lda <- train(classe ~ ., data = train.data, method = 'lda', trControl = train.control)
# Compare accuracy
results <- resamples(list(knn=model.knn, svm=model.svm, lda=model.lda))
summary(results)
summary(results)
summary(model.lda)
finalPredict <- predict(model.lda, raw.test)
finalPredict
finalPredict <- predict(model.svm, raw.test)
finalPredict
finalPredict <- predict(model.knn, raw.test)
finalPredict
View(raw.test)
finalPredict <- predict(model.knn, newdata=raw.test)
finalPredict
summary(results)
dim(raw.train)
dim(raw.test)
keepCol <- colSums(is.na(raw.test)) < nrow(raw.test)
clean.test <- raw.test[,keepCol]
finalPredict <- predict(model.knn, newdata=raw.test)
finalPredict
finalPredict <- predict(model.lda, newdata=raw.test)
finalPredict
View(train.data)
View(train.data$classe)
model.knn$finalModel
predict(model.knn$finalModel, newdata = raw.test)
model.knn$finalModel
model.svm$finalModel
finalPredict <- predict(model.knn, newdata=raw.test)
finalPredict
finalPredict <- predict(model.svm, newdata=raw.test)
finalPredict
View(raw.test)
finalPredict <- predict(model.svm, newdata=clean.test)
finalPredict
View(clean.test)
View(clean.test[,-c(1)])
View(clean.test[,-c(1:3)])
View(clean.test[,-c(1:4)])
View(clean.test[,-c(1:5)])
finalPredict <- predict(model.svm, newdata=lean.test[,-c(1:5)])
finalPredict <- predict(model.svm, newdata=clean.test[,-c(1:5)])
finalPredict <- predict(model.svm, newdata=clean.test[,-c(1:5)])
finalPredict <- predict(model.svm, newdata = clean.test[,-c(1:5)])
clean.test[,-c(1:5)]
finalPredict <- predict(model.svm, newdata = clean.test[,-c(1:5)])
finalPredict <- predict(model.svm, newdata = clean.test[,-c(2:5)])
finalPredict <- predict(model.svm, newdata = clean.test[,-c(3:5)])
# Remove useless information
clean.test <- clean.test[,-c(1:5)]
clean.train <- clean.train[,-c(1:5)]
clean.train$classe <- factor(clean.train$classe)
clean.test$classe
clean.train$classe <- factor(clean.train$classe)
# Remove any data that contains NA in the any columns
clean.trainNoNA <- data.frame(na.omit(clean.train))
dim(clean.trainNoNA)
train <- data.frame()
train.data <- clean.trainNoNA
train.control <- trainControl(method = 'cv', number = 5)
predictions <- data.frame()
model.knn <- train(classe ~ ., data = train.data, method = 'knn', trControl = train.control)
model.svm <- train(classe ~ ., data = train.data, method = 'svmRadial', trControl = train.control)
model.lda <- train(classe ~ ., data = train.data, method = 'lda', trControl = train.control)
# Compare accuracy
results <- resamples(list(knn=model.knn, svm=model.svm, lda=model.lda))
summary(results)
summary(model.lda)
finalPredict <- predict(model.svm, newdata = clean.test)
finalPredict
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
# knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(GGally)
library(caret)
library(klaR)
library(kernlab)
library(corrplot)
set.seed(666)
# Compare accuracy
results <- resamples(list(knn=model.knn, svm=model.svm, lda=model.lda))
summary(results)
summary(results)
trainPredict <- predict(model.svm, newdata = clean.train)
confusionMatrix(trainPredict, clean.train$classe)
train <- data.frame()
forTrain <- data.frame()
fortrain.data <- clean.trainNoNA
# knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(GGally)
library(caret)
library(klaR)
library(kernlab)
library(corrplot)
set.seed(666)
raw <- data.frame()
raw.test  <- read.csv(file = 'pml-testing.csv', header = TRUE)
raw.train <- read.csv(file = 'pml-training.csv', header = TRUE)
dim(raw.train)
# Calculating the percentage of test to training data provided
(dim(raw.test)[1]/dim(raw.train)[1]) * 100
# Percentage of classes
percentage <- prop.table(table(raw.train$classe)) * 100
cbind(freq=table(raw.train$classe), percentage = percentage)
# Clean data, clean data which contains only NA values
clean <- data.frame()
keepCol <- colSums(is.na(raw.test)) < nrow(raw.test)
clean.test <- raw.test[,keepCol]
clean.train <- raw.train[,keepCol]
# Remove useless information
clean.test <- clean.test[,-c(1:5)]
clean.train <- clean.train[,-c(1:5)]
clean.train$classe <- factor(clean.train$classe)
# Remove any data that contains NA in the any columns
clean.trainNoNA <- data.frame(na.omit(clean.train))
dim(clean.trainNoNA)
forTrain <- data.frame()
forTrain.data <- clean.trainNoNA
forTrain.control <- trainControl(method = 'cv', number = 5)
predictions <- data.frame()
model.knn <- train(classe ~ ., data = forTrain.data, method = 'knn', trControl = forTrain.control)
model.svm <- train(classe ~ ., data = forTrain.data, method = 'svmRadial', trControl = forTrain.control)
model.lda <- train(classe ~ ., data = forTrain.data, method = 'lda', trControl = forTrain.control)
# Compare accuracy
results <- resamples(list(knn=model.knn, svm=model.svm, lda=model.lda))
summary(results)
summary(model.svm)
summary(model.svm)
summary(model.svm)
## Sample Error
Using our svm model to predict our training model, we get an out of sample error of 5.28%.
```{r echo = true}
trainPredict <- predict(model.svm, newdata = clean.train)
confusionMatrix(trainPredict, clean.train$classe)
```
## Final Prediction
```{r echo=true}
finalPredict <- predict(model.svm, newdata = clean.test)
finalPredict
```
summary(results)
summary(model.svm)
# Compare accuracy
results <- resamples(list(knn=model.knn, svm=model.svm, lda=model.lda))
summary(results)
summary(model.svm)
trainPredict <- predict(model.svm, newdata = clean.train)
confusionMatrix(trainPredict, clean.train$classe)
finalPredict <- predict(model.svm, newdata = clean.test)
finalPredict
library(knitr)
forTrain
forTrain <- data.frame()
forTrain.data <- clean.trainNoNA
forTrain
something.meow <- clean.trainNoNA
forTrain.data <- clean.trainNoNA
knit('assignment-1.Rmd', encoding = 'UTF-8')
knit('./assignment-1.Rmd', encoding = 'UTF-8')
knitr::opts_chunk$set(echo = TRUE)
unlink('C:/Users/jiash/Dropbox/R-repo/c8-cp1/assignment-1_cache', recursive = TRUE)
library(readr)
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(GGally)
library(caret)
library(klaR)
library(kernlab)
library(corrplot)
library(knitr)
set.seed(666)
raw.test  <- read_csv(file = 'pml-testing.csv', header = TRUE)
read_csv
raw.test  <- read_csv(file = 'pml-testing.csv', col_names = TRUE)
raw.train <- read_csv(file = 'pml-training.csv', col_names = TRUE)
View(raw.train)
dim(raw.test)
dim(raw.train)
# Calculating the percentage of test to training data provided
(dim(raw.test)[1]/dim(raw.train)[1]) * 100
# Percentage of classes
percentage <- prop.table(table(raw.train$classe)) * 100
cbind(freq=table(raw.train$classe), percentage = percentage)
# Clean data, clean data which contains only NA values
clean <- data.frame()
keepCol <- colSums(is.na(raw.test)) < nrow(raw.test)
clean.test <- raw.test[,keepCol]
clean.train <- raw.train[,keepCol]
# Remove useless information
clean.test <- clean.test[,-c(1:5)]
clean.train <- clean.train[,-c(1:5)]
View(clean.train)
library(readr)
raw <- data.frame()
raw.test  <- read_csv(file = 'pml_testing.csv', col_names = TRUE)
raw.train <- read_csv(file = 'pml_training.csv', col_names = TRUE)
getwd()
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
getwd()
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
getwd()
setwd("C:/Users/jiash/Dropbox/R-repo/c8-cp1/")
raw.test  <- read_csv(file = 'pml_testing.csv', col_names = TRUE)
raw.train <- read_csv(file = 'pml_training.csv', col_names = TRUE)
getwd()
raw.test  <- read_csv(file = 'pml_testing.csv', col_names = TRUE)
raw.test
raw.test  <- read_csv(file = './data/pml_testing.csv', col_names = TRUE)
raw.train <- read_csv(file = './data/pml_training.csv', col_names = TRUE)
getwd()
raw.test  <- read_csv(file = './data/pml_testing.csv', col_names = TRUE)
